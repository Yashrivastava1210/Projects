{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57368b23",
   "metadata": {},
   "source": [
    "##### Note: \n",
    "There were issues with kernel while submitting, hence I am submitting the file with clear outputs. I apologize for the problems it may create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72dc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3148ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f94fa52300f424981db3367e433baf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eafce89d08841718f632063bb7861f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ed0e3aa29c4fbba2c6312abae0f630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fca1d5929c246ac88377e328b204ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.MNIST('./data', train = True, download = True, transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,),(0.3081,))]))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 50, shuffle = True)\n",
    "print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7aae178",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torchvision.datasets.MNIST('./data', train = False, download = True, transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,),(0.3081,))]))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef96f4",
   "metadata": {},
   "source": [
    "## 1. Create a CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43148be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn_model, self).__init__()\n",
    "    \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(1, 16, [5, 5], [1, 1], [0, 0], [1, 1])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d([2, 2], [1, 1], [0, 0], [1, 1])\n",
    "     \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(16, 32, [5, 5], [1, 1], [0, 0], [1, 1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d([2, 2], [2, 2], [0, 0], [1, 1])\n",
    "        \n",
    "        # Fully connected 1\n",
    "        self.fc1 = nn.Linear(2592, 50)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        # Fully connected 2\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "#         Forward Propagation Layer\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a843a",
   "metadata": {},
   "source": [
    "## 2. Train the CNN model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2be8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "model = Cnn_model()\n",
    "\n",
    "# Cross Entropy Loss Function\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e9f27b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-47d63acadfc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Forward propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Calculate softmax and ross entropy loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1073206a093e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Convolution 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        if count % 2000 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 2000 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, [loss.data], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.ylim((0.0,0.001))\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim((99,99.7))\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026398f6",
   "metadata": {},
   "source": [
    "### 3. Train the CNN model by changing the optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(1,4):\n",
    "    model_for_optimizers = Cnn_model()\n",
    "    if num == 1:\n",
    "        new_optimizer = torch.optim.SGD(model_for_optimizers.parameters(), lr=0.1, momentum = 0.5)\n",
    "    elif num == 2:\n",
    "        new_optimizer = torch.optim.Adam(model_for_optimizers.parameters(), lr=0.1)\n",
    "    elif num == 3:\n",
    "        new_optimizer = torch.optim.RMSprop(model_for_optimizers.parameters(), lr=0.1)\n",
    "    \n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):        \n",
    "            labels = Variable(labels)                    \n",
    "            new_optimizer.zero_grad()            \n",
    "            outputs = model_for_optimizers(images)\n",
    "            loss = error(outputs, labels)\n",
    "            loss.backward()\n",
    "            new_optimizer.step()\n",
    "            count += 1\n",
    "            if count % 2000 == 0:                         \n",
    "                correct = 0\n",
    "                total = 0                \n",
    "                for images, labels in test_loader:                                    \n",
    "                    outputs = model_for_optimizers(images)                                    \n",
    "                    predicted = torch.max(outputs.data, 1)[1]                                    \n",
    "                    total += len(labels)                \n",
    "                    correct += (predicted == labels).sum()            \n",
    "                accuracy = 100 * correct / float(total)                            \n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "    if num == 1:\n",
    "        print(\"CNN: GD with momentum: \")\n",
    "    elif num == 2:\n",
    "        print(\"CNN: MSProp: \")\n",
    "    elif num == 3:\n",
    "        print(\"CNN: Adam optimizers: \")            \n",
    "    \n",
    "    plt.plot(iteration_list,loss_list)\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f89fa",
   "metadata": {},
   "source": [
    "The best optimizer for this problem is SGD with momentum = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7756d5f",
   "metadata": {},
   "source": [
    "### 4. Train the CNN model by changing minibatch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1,100,1000,10000]\n",
    "\n",
    "for batch in batch_sizes:\n",
    "    train_var_batch = torch.utils.data.DataLoader(train, batch_size = batch, shuffle = True)\n",
    "    test_var_batch = torch.utils.data.DataLoader(test, batch_size = batch, shuffle = True)\n",
    "    \n",
    "    epochs = 10\n",
    "    model_for_batch = Cnn_model()\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model_for_batch.parameters(), lr=0.1, momentum= 0.5)\n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "    time = 0\n",
    "    for epoch in range(epochs):\n",
    "        start = timeit.timeit()\n",
    "        for i, (images, labels) in enumerate(train_var_batch):        \n",
    "            labels = Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_for_batch(images)\n",
    "            loss = error(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            if count % 2000 == 0:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in test_var_batch:                            \n",
    "                    outputs = model_for_batch(images)                            \n",
    "                    predicted = torch.max(outputs.data, 1)[1]                        \n",
    "                    total += len(labels)                \n",
    "                    correct += (predicted == labels).sum()\n",
    "                accuracy = 100 * correct / float(total)\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "        end = timeit.timeit()\n",
    "        time += (end-start)\n",
    "    print(\"Average time taken per epoch for batch size \",batch,\" is: \", time/10)\n",
    "    print(\"\\nBatch Size: \",batch)\n",
    "    plt.plot(iteration_list,loss_list)\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a0fc3",
   "metadata": {},
   "source": [
    "The larger minibatch runs faster than smaller batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ede91",
   "metadata": {},
   "source": [
    "### 5. Train the CNN model by changing learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874df1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1,0.01,0.001,0.0001]\n",
    "for rate in learning_rates:\n",
    "    model_for_learning_rate = Cnn_model()\n",
    "    optimizer_var_lr = torch.optim.SGD(model_for_learning_rate.parameters(), lr=rate, momentum = 0.5)\n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):                            \n",
    "            optimizer_var_lr.zero_grad()            \n",
    "            outputs = model_for_learning_rate(images)\n",
    "            loss = error(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_var_lr.step()\n",
    "            count += 1\n",
    "            if count % 2000 == 0:                         \n",
    "                correct = 0\n",
    "                total = 0                \n",
    "                for images, labels in test_loader:                                    \n",
    "                    outputs = model_for_learning_rate(images)                                    \n",
    "                    predicted = torch.max(outputs.data, 1)[1]                                    \n",
    "                    total += len(labels)                \n",
    "                    correct += (predicted == labels).sum()            \n",
    "                accuracy = 100 * correct / float(total)                            \n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "    print(\"Learning Rate: \",rate)\n",
    "    plt.plot(iteration_list,loss_list)\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9209c72",
   "metadata": {},
   "source": [
    "The best learning rate in terms of convergence is 0.1 since it reaches the maximum value faster and does not deviates much after that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe3722",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Took help from Mohit Tuli(mtuli@iu.edu) for pytorch tutorial and explanations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
